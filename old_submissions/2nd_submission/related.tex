\section{Related Work}
\label{sec:prior_work}
%
We review previous work on material parameter estimation in computer graphics and vision, as well as on Hamiltonian Monte Carlo methods in Bayesian inference.

\paragraph{Per-pixel SVBRDF capture.} A large amount of previous work focuses on acquisition of material data from physical measurements. The methods generally observe the material sample with a fixed camera position, and solve for the parameters of a spatially-varying BRDF model such as diffuse albedo, roughness (glossiness) and surface normal. They differ in the number of light patterns required and their type; the patterns used include moving linear light \cite{Gardner2003}, Gray code patterns \cite{Francken2009} and spherical harmonic illumination \cite{Ghosh2009}. In these approaches, the model and its optimization are specific to the light patterns and the optical setup of the method, as general non-linear optimization was historically deemed  inefficient and not robust enough.

More recently, Aittala et al. \cite{Aittala2013} captured per-pixel SVBRDF data using Fourier patterns projected using an LCD screen; their algorithm used a fairly general, differentiable forward evaluation model, which was inverted in a maximum a-posteriori (MAP) framework. In practice, this was done using a standard non-linear least-squares optimizer with well-chosen priors, showing that a general optimization approach with a differentiable forward model can be successful with carefully chosen illumination patterns, priors and initialization.

Later work by Aittala et al. \cite{Aittala2015,Aittala2016} found per-pixel parameters of stationary spatially-varying SVBRDFs from two-shot and one-shot flash-lit photographs, respectively. In the latter case, the approach used a neural Gram-matrix texture descriptor based on the texture synthesis and feature transfer work of Gatys \cite{Gatys2015,Gatys2016} to compare renderings with similar texture patterns but without pixel alignment. We demonstrate that this descriptor makes an excellent summary function within our framework; in fact, the approach works well in our case, as the procedural nature of the model serves as an additional implicit prior, compared to per-pixel approaches. On the other hand, our forward evaluation process is more complex than Aittala et al., since it also includes the procedural material generation itself.

Recent methods by Deschaintre et al. \cite{Deschaintre2018}, Li et al. \cite{Li2018} have been able to capture non-stationary SVBRDFs from a single flash photograph by training an end-to-end deep convolutional network. Gao et al. \cite{Gao2019} introduced an auto-encoder approach, optimizing the appearance match in the latent space. All of these approaches estimate per-pixel parameters of the microfacet model (diffuse albedo, roughness, normal), and are not obviously applicable to estimation of procedural model parameters, nor to more advanced optical models (significant anisotropy, layering or scattering).

\paragraph{Procedural material parameter estimation.} Focus on estimating the parameters of procedural models has been relatively rare. The dual-scale glossy parameter estimation work of Wang et al. \cite{Wang2011} finds, under step-edge lighting, the parameters of a bumpy surface model consisting of a heightfield constructed from a Gaussian noise power spectrum and global microfacet material parameters. Their results provide impressive accuracy, but the solution is highly specialized for this material model and illumination.

Recently, Hu et al. \cite{Hu2019} introduced a method for inverse procedural material modeling that treats the material as a black box, and trains a neural network mapping images to parameter vector predictions. The training data comes from sampling the space of parameters and evaluating the black box model. In our experiments, this approach is less accurate; our fully differentiable models can achieve higher accuracy fits and can be used to explore posterior distributions through sampling.

\paragraph{Optical parameters of fiber-based models.} Several approaches for rendering of fabrics model the material at the microscopic fiber level \cite{Zhao2011,Zhao2016,Leaf2018}. However, the optical properties of the fibers (e.g. roughness, scattering albedo) have to be chosen separately to match real examples. Zhao et al. \cite{Zhao2011} use a simple but effective trick of matching the mean and standard deviation (in RGB) of the pixels in a well-chosen area of the target and simulated image. Khungurn et al. \cite{Khungurn2015} have extended this approach with a differentiable volumetric renderer, combined with a stochastic gradient descent; however, their method is still specific to fiber-level modeling of cloth.

\paragraph{Bayesian inference.} A variety of methods used across the sciences are Bayesian in nature; in this paper, we specifically explore Bayesian inference for parameter estimation through Markov chain Monte Carlo sampling of the posterior distribution. Hamiltonian Monte Carlo (HMC) \cite{Neal2012,Betancourt2017} is an algorithm for sampling a multi-dimensional continuous probability distribution (pdf): given just a piece of code that evaluates the log pdf and its gradient, the method can effectively explore the space, sampling points with probability proportional to the pdf. The gradient information leads to more efficient sampling than simpler methods such as Metropolis-Hastings.

Several software packages exist for Bayesian inference, allowing a user to specify a statistical forward model and parameters. The posterior distribution can then be sampled using HMC or maximized using a non-linear optimizer. An example is STAN \cite{Stan}. Our earlier version was based on STAN; however, its custom forward models use C++, which we found limiting. We reimplemented key features of Stan (HMC, sigmoid transforms of parameters) in PyTorch, which gave our system higher flexibility and extensibility.


